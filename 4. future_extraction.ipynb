{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0264cd40",
   "metadata": {},
   "source": [
    "# Описание\n",
    "В данном ноутбуке выполняется преобразование текстов из столбца 'source_name_model' в усреднённые эмбеддинги токенов с использованием предобученной модели 'cointegrated/rubert-tiny2'. Для каждого текста рассчитывается mean pooling по скрытым представлениям всех непаддинговых токенов. Полученные эмбеддинги, вместе с дополнительными признаками ('cat_id', 'самовывоз', 'возможность доставки', 'гарантия'), используются для формирования финального датасета, пригодного для последующего обучения модели машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6fc1e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc='Tokenizing rows')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ba06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('full_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6646510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cointegrated/rubert-tiny2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84576352",
   "metadata": {},
   "source": [
    "# future_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(text) -> str:\n",
    "    \"\"\"\n",
    "    Простая очистка текста.\n",
    "    \"\"\"\n",
    "    text = str(\n",
    "        text\n",
    "    ) if text is not None else ''  # преобразуем text в строку, если это не строка\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^а-яёa-z0-9\\s.,*!?:-]', '',\n",
    "                  text)  # удаление лишних символов (кроме пунктуации)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # удаление лишних пробелов\n",
    "    return text\n",
    "\n",
    "\n",
    "# применяем ко всему датасету\n",
    "df['source_name_model'] = df['source_name_model'].apply(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Получает эмбеддинг текста с использованием mean pooling \n",
    "    по всем токенам (кроме паддинга).\n",
    "    \n",
    "    :param text: входной текст\n",
    "    :return: усреднённый эмбеддинг по всем токенам\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(text,\n",
    "                       return_tensors='pt',\n",
    "                       truncation=True,\n",
    "                       padding='max_length',\n",
    "                       max_length=27)\n",
    "\n",
    "    # переносим данные на GPU, если он есть\n",
    "    tokens = {key: val.to(device) for key, val in tokens.items()}\n",
    "\n",
    "    with torch.no_grad():  # выключаем градиенты\n",
    "        output = model(**tokens)\n",
    "        last_hidden_state = output.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "        attention_mask = tokens['attention_mask']  # [batch_size, seq_len]\n",
    "\n",
    "        # применяем attention mask: обнуляем эмбеддинги паддингов\n",
    "        mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size())\n",
    "        masked_embeddings = last_hidden_state * mask\n",
    "\n",
    "        # усреднение по непаддинговым токенам\n",
    "        summed = masked_embeddings.sum(dim=1)\n",
    "        counts = mask.sum(dim=1)  # число непаддинговых токенов\n",
    "        mean_pooled = summed / counts\n",
    "\n",
    "    return mean_pooled.cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечение значений из датасета\n",
    "texts = df['source_name_model'].tolist()\n",
    "labels = df['cat_id'].values  # метки классов\n",
    "pickup = df['самовывоз'].values\n",
    "delivery = df['возможность доставки'].values\n",
    "guarantee = df['гарантия'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем тексты в эмбеддинги\n",
    "embeddings = np.array([get_bert_embedding(text) for text in tqdm(texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# состовляем финальный датасет для последующего обучения на нем модели\n",
    "final_dataset = pd.DataFrame(embeddings)\n",
    "final_dataset['pickup'] = pickup\n",
    "final_dataset['delivery'] = delivery\n",
    "final_dataset['guarantee'] = guarantee\n",
    "final_dataset['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем финальный датасет\n",
    "final_dataset.to_parquet('final_dataset.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
